{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BabyHacker0/mini_proj/blob/main/pdf_openai1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnrxf6FWQsh9",
        "outputId": "23965368-7d78-4078-ebd5-b77d68b2a65a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.12-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.2.13-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langchainhub\n",
            "  Downloading langchainhub-0.1.21-py3-none-any.whl.metadata (659 bytes)\n",
            "Collecting chromadb\n",
            "  Downloading chromadb-0.5.23-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.3.12)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.57.4)\n",
            "Collecting pypdf\n",
            "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.11.10)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting httpx-sse<0.5.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.25 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.3.25)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.125 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.3)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.7.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (9.0.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.11.6)\n",
            "Collecting langchain-core<0.4.0,>=0.3.25 (from langchain_community)\n",
            "  Downloading langchain_core-0.3.27-py3-none-any.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (24.2)\n",
            "Collecting types-requests<3.0.0.0,>=2.31.0.2 (from langchainhub)\n",
            "  Downloading types_requests-2.32.0.20241016-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.10.3)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Downloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvicorn-0.34.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-3.7.4-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.29.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Downloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.29.0)\n",
            "Collecting tokenizers<=0.20.3,>=0.13.2 (from chromadb)\n",
            "  Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.67.1)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.5)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.68.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.1)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-31.0.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.12)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.3.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.2.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.23.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting starlette<0.42.0,>=0.40.0 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.2.3)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.25->langchain_community) (1.33)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.3,>=0.1.125->langchain_community) (1.0.0)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (4.25.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.15)\n",
            "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.66.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting opentelemetry-proto==1.29.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Downloading opentelemetry_proto-1.29.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting opentelemetry-instrumentation==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.50b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.50b0)\n",
            "Collecting opentelemetry-util-http==0.50b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.0)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.50b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.27.1)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.4.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<=0.20.3,>=0.13.2->chromadb) (0.27.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (14.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<=0.20.3,>=0.13.2->chromadb) (2024.10.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.25->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Downloading langchain_community-0.3.12-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.13-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchainhub-0.1.21-py3-none-any.whl (5.2 kB)\n",
            "Downloading chromadb-0.5.23-py3-none-any.whl (628 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m628.3/628.3 kB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-4.2.1-cp39-abi3-manylinux_2_28_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.8/94.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.27-py3-none-any.whl (411 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m411.5/411.5 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.0.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.20.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (13.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.29.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_exporter_otlp_proto_common-1.29.0-py3-none-any.whl (18 kB)\n",
            "Downloading opentelemetry_proto-1.29.0-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_instrumentation_fastapi-0.50b0-py3-none-any.whl (12 kB)\n",
            "Downloading opentelemetry_instrumentation-0.50b0-py3-none-any.whl (30 kB)\n",
            "Downloading opentelemetry_instrumentation_asgi-0.50b0-py3-none-any.whl (16 kB)\n",
            "Downloading opentelemetry_util_http-0.50b0-py3-none-any.whl (6.9 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading posthog-3.7.4-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.8/54.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.7.0-py3-none-any.whl (29 kB)\n",
            "Downloading tokenizers-0.20.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_requests-2.32.0.20241016-py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.34.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
            "Downloading httptools-0.6.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.1/442.1 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.23.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Downloading protobuf-5.29.2-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.2/73.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading uvloop-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (443 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.8/443.8 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
            "Downloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53725 sha256=547c49a5a97821441d78b30a6c275e5abcf82878593c18fca35b8700ac728432\n",
            "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, monotonic, durationpy, uvloop, uvicorn, types-requests, python-dotenv, pyproject_hooks, pypdf, protobuf, overrides, opentelemetry-util-http, mypy-extensions, mmh3, marshmallow, humanfriendly, httpx-sse, httptools, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, typing-inspect, tiktoken, starlette, posthog, opentelemetry-proto, langchainhub, coloredlogs, build, tokenizers, pydantic-settings, opentelemetry-exporter-otlp-proto-common, onnxruntime, kubernetes, fastapi, dataclasses-json, opentelemetry-instrumentation, langchain-core, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, langchain-openai, opentelemetry-instrumentation-fastapi, langchain_community, chromadb\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: tokenizers\n",
            "    Found existing installation: tokenizers 0.21.0\n",
            "    Uninstalling tokenizers-0.21.0:\n",
            "      Successfully uninstalled tokenizers-0.21.0\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.25\n",
            "    Uninstalling langchain-core-0.3.25:\n",
            "      Successfully uninstalled langchain-core-0.3.25\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 5.29.2 which is incompatible.\n",
            "transformers 4.47.0 requires tokenizers<0.22,>=0.21, but you have tokenizers 0.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.1 build-1.2.2.post1 chroma-hnswlib-0.7.6 chromadb-0.5.23 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.9 fastapi-0.115.6 httptools-0.6.4 httpx-sse-0.4.0 humanfriendly-10.0 kubernetes-31.0.0 langchain-core-0.3.27 langchain-openai-0.2.13 langchain_community-0.3.12 langchainhub-0.1.21 marshmallow-3.23.2 mmh3-5.0.1 monotonic-1.6 mypy-extensions-1.0.0 onnxruntime-1.20.1 opentelemetry-exporter-otlp-proto-common-1.29.0 opentelemetry-exporter-otlp-proto-grpc-1.29.0 opentelemetry-instrumentation-0.50b0 opentelemetry-instrumentation-asgi-0.50b0 opentelemetry-instrumentation-fastapi-0.50b0 opentelemetry-proto-1.29.0 opentelemetry-util-http-0.50b0 overrides-7.7.0 posthog-3.7.4 protobuf-5.29.2 pydantic-settings-2.7.0 pypdf-5.1.0 pypika-0.48.9 pyproject_hooks-1.2.0 python-dotenv-1.0.1 starlette-0.41.3 tiktoken-0.8.0 tokenizers-0.20.3 types-requests-2.32.0.20241016 typing-inspect-0.9.0 uvicorn-0.34.0 uvloop-0.21.0 watchfiles-1.0.3\n"
          ]
        }
      ],
      "source": [
        "! pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain openai pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "adPfPOkcRDSO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['LANGCHAIN_API_KEY'] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FVNHbdcuRGj3"
      },
      "outputs": [],
      "source": [
        "os.environ['OPENAI_API_KEY'] = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "o4QQGwPVRS-a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mW1PAJggVfBF",
        "outputId": "5675770d-8f1d-4754-bce6-fb3bd78e56ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.34.0)\n",
            "Requirement already satisfied: sentence-transformers in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.2)\n",
            "Requirement already satisfied: langchain in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.3.13)\n",
            "Requirement already satisfied: torch in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.0.1)\n",
            "Requirement already satisfied: faiss-cpu in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.9.0.post1)\n",
            "Requirement already satisfied: numpy in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.26.4)\n",
            "Requirement already satisfied: langchain_community in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.3.11)\n",
            "Requirement already satisfied: langchain_huggingface in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.1.2)\n",
            "Requirement already satisfied: huggingface_hub in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.17.3)\n",
            "Requirement already satisfied: filelock in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.15,>=0.14 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: torchvision in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (0.15.2)\n",
            "Requirement already satisfied: scikit-learn in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.6.0)\n",
            "Requirement already satisfied: scipy in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: nltk in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (3.9.1)\n",
            "Requirement already satisfied: sentencepiece in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from sentence-transformers) (0.2.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.0.36)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (3.11.10)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.26 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.3.27)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.3.4)\n",
            "Requirement already satisfied: langsmith<0.3,>=0.1.17 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (0.2.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.10.4)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: networkx in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain_community) (0.5.14)\n",
            "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain_community) (0.4.0)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain_community) (2.6.1)\n",
            "Collecting huggingface_hub\n",
            "  Downloading huggingface_hub-0.27.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting sentence-transformers\n",
            "  Using cached sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-huggingface to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain_huggingface\n",
            "  Downloading langchain_huggingface-0.1.1-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading langchain_huggingface-0.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "  Downloading langchain_huggingface-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
            "  Downloading langchain_huggingface-0.0.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "  Downloading langchain_huggingface-0.0.1-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.13-py3-none-any.whl.metadata (2.9 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-huggingface to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_community-0.3.12-py3-none-any.whl.metadata (2.9 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Using cached langchain_community-0.3.11-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_community-0.3.10-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting langsmith<0.3,>=0.1.17 (from langchain)\n",
            "  Using cached langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.9-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Using cached langchain_community-0.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
            "  Downloading SQLAlchemy-2.0.35-cp310-cp310-win_amd64.whl.metadata (9.9 kB)\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.7-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_community-0.3.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_community-0.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_community-0.3.4-py3-none-any.whl.metadata (2.9 kB)\n",
            "  Downloading langchain_community-0.3.3-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading langchain_community-0.3.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "  Downloading langchain_community-0.2.19-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.2.17-py3-none-any.whl.metadata (7.1 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.2.18-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_community-0.2.17-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_community-0.2.16-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_community-0.2.15-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_community-0.2.13-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_community-0.2.12-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_community-0.2.11-py3-none-any.whl.metadata (2.7 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-community to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_community-0.2.10-py3-none-any.whl.metadata (2.7 kB)\n",
            "  Downloading langchain_community-0.2.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_community-0.2.7-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_community-0.2.6-py3-none-any.whl.metadata (2.5 kB)\n",
            "  Downloading langchain_community-0.2.5-py3-none-any.whl.metadata (2.5 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading langchain_community-0.2.4-py3-none-any.whl.metadata (2.4 kB)\n",
            "  Downloading langchain_community-0.2.3-py3-none-any.whl.metadata (9.0 kB)\n",
            "  Downloading langchain_community-0.2.2-py3-none-any.whl.metadata (8.9 kB)\n",
            "  Downloading langchain_community-0.2.1-py3-none-any.whl.metadata (8.9 kB)\n",
            "  Downloading langchain_community-0.2.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "  Downloading langchain_community-0.0.38-py3-none-any.whl.metadata (8.7 kB)\n",
            "  Downloading langchain_community-0.0.37-py3-none-any.whl.metadata (8.7 kB)\n",
            "  Downloading langchain_community-0.0.36-py3-none-any.whl.metadata (8.7 kB)\n",
            "  Downloading langchain_community-0.0.35-py3-none-any.whl.metadata (8.7 kB)\n",
            "  Downloading langchain_community-0.0.34-py3-none-any.whl.metadata (8.5 kB)\n",
            "  Downloading langchain_community-0.0.33-py3-none-any.whl.metadata (8.5 kB)\n",
            "  Downloading langchain_community-0.0.32-py3-none-any.whl.metadata (8.5 kB)\n",
            "  Downloading langchain_community-0.0.31-py3-none-any.whl.metadata (8.4 kB)\n",
            "  Downloading langchain_community-0.0.30-py3-none-any.whl.metadata (8.4 kB)\n",
            "  Downloading langchain_community-0.0.29-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading langchain_community-0.0.28-py3-none-any.whl.metadata (8.3 kB)\n",
            "  Downloading langchain_community-0.0.27-py3-none-any.whl.metadata (8.2 kB)\n",
            "  Using cached langchain_community-0.0.26-py3-none-any.whl.metadata (8.2 kB)\n",
            "  Downloading langchain_community-0.0.25-py3-none-any.whl.metadata (8.1 kB)\n",
            "  Downloading langchain_community-0.0.24-py3-none-any.whl.metadata (8.1 kB)\n",
            "  Downloading langchain_community-0.0.23-py3-none-any.whl.metadata (8.1 kB)\n",
            "  Downloading langchain_community-0.0.22-py3-none-any.whl.metadata (8.1 kB)\n",
            "  Downloading langchain_community-0.0.21-py3-none-any.whl.metadata (8.1 kB)\n",
            "  Downloading langchain_community-0.0.20-py3-none-any.whl.metadata (8.1 kB)\n",
            "  Downloading langchain_community-0.0.19-py3-none-any.whl.metadata (7.9 kB)\n",
            "  Downloading langchain_community-0.0.18-py3-none-any.whl.metadata (7.9 kB)\n",
            "  Downloading langchain_community-0.0.17-py3-none-any.whl.metadata (7.9 kB)\n",
            "  Downloading langchain_community-0.0.16-py3-none-any.whl.metadata (7.8 kB)\n",
            "  Downloading langchain_community-0.0.15-py3-none-any.whl.metadata (7.6 kB)\n",
            "  Downloading langchain_community-0.0.14-py3-none-any.whl.metadata (7.5 kB)\n",
            "  Downloading langchain_community-0.0.13-py3-none-any.whl.metadata (7.5 kB)\n",
            "  Downloading langchain_community-0.0.12-py3-none-any.whl.metadata (7.5 kB)\n",
            "  Downloading langchain_community-0.0.11-py3-none-any.whl.metadata (7.3 kB)\n",
            "  Downloading langchain_community-0.0.10-py3-none-any.whl.metadata (7.3 kB)\n",
            "  Downloading langchain_community-0.0.8-py3-none-any.whl.metadata (7.3 kB)\n",
            "  Downloading langchain_community-0.0.7-py3-none-any.whl.metadata (7.3 kB)\n",
            "  Downloading langchain_community-0.0.6-py3-none-any.whl.metadata (7.2 kB)\n",
            "  Downloading langchain_community-0.0.5-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain_community-0.0.4-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_community-0.0.3-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain_community-0.0.2-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading langchain_community-0.0.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting langchain\n",
            "  Using cached langchain-0.3.13-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.26->langchain) (1.33)\n",
            "  Downloading langchain-0.3.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Using cached langchain-0.3.11-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain-0.3.10-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Using cached langchain-0.3.9-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain-0.3.8-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain-0.3.7-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain-0.3.6-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain-0.3.5-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain-0.3.4-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain-0.3.3-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain-0.3.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain-0.3.1-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.3.0,>=0.2.43 (from langchain)\n",
            "  Downloading langchain_core-0.2.43-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.4-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting text-generation<0.8.0,>=0.7.0 (from langchain_huggingface)\n",
            "  Downloading text_generation-0.7.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.2.16-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain-0.2.15-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain-0.2.14-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain-0.2.13-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain-0.2.12-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain-0.2.11-py3-none-any.whl.metadata (7.1 kB)\n",
            "  Downloading langchain-0.2.10-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading langchain-0.2.9-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading langchain-0.2.8-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading langchain-0.2.7-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading langchain-0.2.6-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain-0.2.5-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain-0.2.4-py3-none-any.whl.metadata (7.0 kB)\n",
            "  Downloading langchain-0.2.3-py3-none-any.whl.metadata (6.9 kB)\n",
            "  Downloading langchain-0.2.2-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.2.1-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.2.0-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.20-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-core<0.2.0,>=0.1.52 (from langchain)\n",
            "  Downloading langchain_core-0.1.53-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.2-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.19-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.17-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.16-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.15-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.14-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.13-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.12-py3-none-any.whl.metadata (13 kB)\n",
            "  Using cached langchain-0.1.11-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.10-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.9-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.8-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.7-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langsmith<0.1,>=0.0.83 (from langchain)\n",
            "  Using cached langsmith-0.0.92-py3-none-any.whl.metadata (9.9 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.6-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.5-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.4-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.3-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langsmith<0.0.84,>=0.0.83 (from langchain)\n",
            "  Downloading langsmith-0.0.83-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.1.1-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.1.0-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.0.354-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.0.353-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.0.352-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.0.351-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.0.350-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.0.349-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-core<0.1,>=0.0.13 (from langchain)\n",
            "  Downloading langchain_core-0.0.13-py3-none-any.whl.metadata (978 bytes)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.348-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: anyio<5,>=3 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain-core<0.1,>=0.0.13->langchain) (4.7.0)\n",
            "  Downloading langchain-0.0.347-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting anyio<4.0 (from langchain)\n",
            "  Downloading anyio-3.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.346-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading langchain-0.0.345-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading langchain-0.0.344-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading langchain-0.0.343-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading langchain-0.0.342-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading langchain-0.0.341-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting langchain-core<0.0.7,>=0.0.6 (from langchain)\n",
            "  Downloading langchain_core-0.0.6-py3-none-any.whl.metadata (750 bytes)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.340-py3-none-any.whl.metadata (16 kB)\n",
            "INFO: pip is looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting langchain-core<0.2,>=0.1.21 (from langchain_community)\n",
            "  Downloading langchain_core-0.1.52-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.51-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.50-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.49-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.48-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.47-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.46-py3-none-any.whl.metadata (5.9 kB)\n",
            "INFO: pip is still looking at multiple versions of langchain-core to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading langchain_core-0.1.45-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.44-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.43-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.42-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.41-py3-none-any.whl.metadata (5.9 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading langchain_core-0.1.40-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.39-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading langchain_core-0.1.38-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.37-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.36-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.35-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.34-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.33-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.32-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.31-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.30-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Using cached langchain_core-0.1.29-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.28-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.27-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.26-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.25-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.24-py3-none-any.whl.metadata (6.0 kB)\n",
            "  Downloading langchain_core-0.1.23-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
            "  Downloading langsmith-0.0.87-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.339-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading langchain-0.0.338-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading langchain-0.0.337-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading langchain-0.0.336-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading langchain-0.0.335-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading langchain-0.0.334-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading langchain-0.0.333-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading langchain-0.0.332-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading langchain-0.0.331-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading langchain-0.0.330-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading langchain-0.0.329-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading langchain-0.0.327-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading langchain-0.0.326-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading langchain-0.0.325-py3-none-any.whl.metadata (16 kB)\n",
            "  Downloading langchain-0.0.324-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.323-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.322-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.321-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.320-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.319-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.318-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.317-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.316-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.315-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.314-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.313-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.312-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.311-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.310-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.309-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.308-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.307-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.306-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (2.10.2)\n",
            "  Downloading langchain-0.0.305-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.304-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.303-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.302-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.301-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.300-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.299-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.298-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.297-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.296-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.295-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.294-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.293-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.292-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.291-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.290-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.289-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.288-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.287-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.286-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.285-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.284-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.283-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.281-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.279-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.278-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.277-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.276-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.275-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.274-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.273-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.272-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting google-api-core<3.0.0,>=2.11.1 (from langchain)\n",
            "  Downloading google_api_core-2.24.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.271-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.270-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.269-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.268-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.267-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langchain) (1.2.4)\n",
            "  Downloading langchain-0.0.266-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting pydantic<2,>=1 (from langchain)\n",
            "  Using cached pydantic-1.10.19-cp310-cp310-win_amd64.whl.metadata (153 kB)\n",
            "Collecting langchain\n",
            "  Using cached langchain-0.0.265-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.264-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.263-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.262-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.261-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.260-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.259-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.258-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.257-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.256-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.255-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.254-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.253-py3-none-any.whl.metadata (15 kB)\n",
            "  Downloading langchain-0.0.252-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.251-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.250-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.249-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.248-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.247-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.246-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.245-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.244-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.243-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.242-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.240-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.239-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.238-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.237-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting langsmith<0.0.11,>=0.0.10 (from langchain)\n",
            "  Downloading langsmith-0.0.10-py3-none-any.whl.metadata (8.7 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.236-py3-none-any.whl.metadata (14 kB)\n",
            "  Downloading langchain-0.0.235-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting langsmith<0.0.8,>=0.0.7 (from langchain)\n",
            "  Downloading langsmith-0.0.7-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.234-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting langsmith<0.0.6,>=0.0.5 (from langchain)\n",
            "  Downloading langsmith-0.0.5-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting langchain\n",
            "  Downloading langchain-0.0.233-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.0.232-py3-none-any.whl.metadata (13 kB)\n",
            "  Downloading langchain-0.0.231-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchainplus-sdk<0.0.21,>=0.0.20 (from langchain)\n",
            "  Downloading langchainplus_sdk-0.0.20-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (0.28.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.12)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\riddhi murugan\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
            "\n",
            "The conflict is caused by:\n",
            "    The user requested langchain\n",
            "    langchain-community 0.3.11 depends on langchain<0.4.0 and >=0.3.11\n",
            "    The user requested langchain\n",
            "    langchain-community 0.3.13 depends on langchain<0.4.0 and >=0.3.13\n",
            "    The user requested langchain\n",
            "    langchain-community 0.3.12 depends on langchain<0.4.0 and >=0.3.12\n",
            "    The user requested langchain\n",
            "    langchain-community 0.3.10 depends on langchain<0.4.0 and >=0.3.10\n",
            "    The user requested langchain\n",
            "    langchain-community 0.3.9 depends on langchain<0.4.0 and >=0.3.8\n",
            "    The user requested langchain\n",
            "    langchain-community 0.3.8 depends on langchain<0.4.0 and >=0.3.8\n",
            "    The user requested langchain\n",
            "    langchain-community 0.3.7 depends on langchain<0.4.0 and >=0.3.7\n",
            "    The user requested langchain\n",
            "    langchain-community 0.3.6 depends on langchain<0.4.0 and >=0.3.7\n",
            "    The user requested langchain\n",
            "    langchain-community 0.3.5 depends on langchain<0.4.0 and >=0.3.6\n",
            "    The user requested langchain\n",
            "    langchain-community 0.3.4 depends on langchain<0.4.0 and >=0.3.6\n",
            "    The user requested langchain\n",
            "    langchain-community 0.3.3 depends on langchain<0.4.0 and >=0.3.4\n",
            "    The user requested langchain\n",
            "    langchain-community 0.3.2 depends on langchain<0.4.0 and >=0.3.3\n",
            "    The user requested langchain\n",
            "    langchain-community 0.3.1 depends on langchain<0.4.0 and >=0.3.1\n",
            "    The user requested langchain\n",
            "    langchain-community 0.3.0 depends on langchain<0.4.0 and >=0.3.0\n",
            "    The user requested langchain\n",
            "    langchain-community 0.2.19 depends on langchain<0.3.0 and >=0.2.17\n",
            "    The user requested langchain\n",
            "    langchain-community 0.2.18 depends on langchain<0.3.0 and >=0.2.17\n",
            "    The user requested langchain\n",
            "    langchain-community 0.2.17 depends on langchain<0.3.0 and >=0.2.16\n",
            "    The user requested langchain\n",
            "    langchain-community 0.2.16 depends on langchain<0.3.0 and >=0.2.16\n",
            "    The user requested langchain\n",
            "    langchain-community 0.2.15 depends on langchain<0.3.0 and >=0.2.15\n",
            "    The user requested langchain\n",
            "    langchain-community 0.2.13 depends on langchain<0.3.0 and >=0.2.15\n",
            "    The user requested langchain\n",
            "    langchain-community 0.2.12 depends on langchain<0.3.0 and >=0.2.13\n",
            "    The user requested langchain\n",
            "    langchain-community 0.2.11 depends on langchain<0.3.0 and >=0.2.12\n",
            "    The user requested langchain\n",
            "    langchain-community 0.2.10 depends on langchain<0.3.0 and >=0.2.9\n",
            "    The user requested langchain\n",
            "    langchain-community 0.2.9 depends on langchain<0.3.0 and >=0.2.9\n",
            "    The user requested langchain\n",
            "    langchain-community 0.2.7 depends on langchain<0.3.0 and >=0.2.7\n",
            "    The user requested langchain\n",
            "    langchain-community 0.2.6 depends on langchain<0.3.0 and >=0.2.6\n",
            "    The user requested langchain\n",
            "    langchain-community 0.2.5 depends on langchain<0.3.0 and >=0.2.5\n",
            "    The user requested langchain\n",
            "    langchain-community 0.2.4 depends on langchain<0.3.0 and >=0.2.0\n",
            "    The user requested langchain\n",
            "    langchain-community 0.2.3 depends on langchain<0.3.0 and >=0.2.0\n",
            "    The user requested langchain\n",
            "    langchain-community 0.2.2 depends on langchain<0.3.0 and >=0.2.0\n",
            "    The user requested langchain\n",
            "    langchain-community 0.2.1 depends on langchain<0.3.0 and >=0.2.0\n",
            "    The user requested langchain\n",
            "    langchain-community 0.2.0 depends on langchain<0.3.0 and >=0.2.0\n",
            "\n",
            "To fix this you could try to:\n",
            "1. loosen the range of package versions you've specified\n",
            "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
            "\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR: Cannot install langchain, langchain-community==0.2.0, langchain-community==0.2.1, langchain-community==0.2.10, langchain-community==0.2.11, langchain-community==0.2.12, langchain-community==0.2.13, langchain-community==0.2.15, langchain-community==0.2.16, langchain-community==0.2.17, langchain-community==0.2.18, langchain-community==0.2.19, langchain-community==0.2.2, langchain-community==0.2.3, langchain-community==0.2.4, langchain-community==0.2.5, langchain-community==0.2.6, langchain-community==0.2.7, langchain-community==0.2.9, langchain-community==0.3.0, langchain-community==0.3.1, langchain-community==0.3.10, langchain-community==0.3.11, langchain-community==0.3.12, langchain-community==0.3.13, langchain-community==0.3.2, langchain-community==0.3.3, langchain-community==0.3.4, langchain-community==0.3.5, langchain-community==0.3.6, langchain-community==0.3.7, langchain-community==0.3.8 and langchain-community==0.3.9 because these package versions have conflicting dependencies.\n",
            "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
          ]
        }
      ],
      "source": [
        "pip install transformers sentence-transformers langchain torch faiss-cpu numpy langchain_community langchain_huggingface huggingface_hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ldC7PfLswSY4"
      },
      "outputs": [],
      "source": [
        "# Download documents about IPC/BNS to local directory.\n",
        "from urllib.request import urlretrieve\n",
        "os.makedirs(\"legal_doc\", exist_ok=True)\n",
        "files = [\n",
        "    \"https://www.indiacode.nic.in/bitstream/123456789/20062/1/a2023-45.pdf\",\n",
        "    \"https://www.mha.gov.in/sites/default/files/250883_english_01042024.pdf\",\n",
        "\n",
        "]\n",
        "for url in files:\n",
        "    file_path = os.path.join(\"legal_doc\", url.rpartition(\"/\")[2])\n",
        "    urlretrieve(url, file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "i9wzRUaJXGco"
      },
      "outputs": [],
      "source": [
        "# Define a custom prompt template\n",
        "prompt_template = \"\"\"\n",
        "You are an expert assistant. Use the following context to answer the question accurately and concisely:\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "# Replace `prompt = hub.pull(\"rlm/rag-prompt\")` with this template\n",
        "from langchain.prompts import PromptTemplate\n",
        "prompt = PromptTemplate(input_variables=[\"context\", \"question\"], template=prompt_template)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvkkcVVnXUz1",
        "outputId": "3fb5b2a5-eadc-4047-b934-7ba9df4c1aaf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Riddhi Murugan\\AppData\\Local\\Temp\\ipykernel_23616\\90664333.py:42: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "content='Offences related to public servants include disobeying the law with intent to cause injury, framing incorrect documents, engaging in unlawful trade, buying property unlawfully, personating a public servant, wearing garb with fraudulent intent, absconding to avoid service of summons, preventing service of summons, and non-attendance in obedience to an order from a public servant.' additional_kwargs={} response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 877, 'total_tokens': 950, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-de42a21e-6fd7-4350-8837-d69107237f45-0'\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Set up OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\"\n",
        "\n",
        "# Load PDF files\n",
        "loader = PyPDFDirectoryLoader(\"./legal_doc/\")\n",
        "docs = loader.load()\n",
        "\n",
        "# Split documents into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "# Create Chroma vectorstore\n",
        "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
        "\n",
        "# Retriever\n",
        "retriever = vectorstore.as_retriever()\n",
        "\n",
        "# Define a custom prompt template\n",
        "prompt_template = \"\"\"\n",
        "You are an expert assistant. Use the following context to answer the question accurately and concisely:\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "prompt = PromptTemplate(input_variables=[\"context\", \"question\"], template=prompt_template)\n",
        "\n",
        "# Initialize LLM\n",
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "\n",
        "# Post-processing function\n",
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
        "\n",
        "# RAG Chain (without StrOutputParser)\n",
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        ")\n",
        "\n",
        "# Ask a question\n",
        "response = rag_chain.invoke(\"What are offences related to public servants?\")\n",
        "print(response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iswteW2HSTfY"
      },
      "outputs": [],
      "source": [
        "# Documents\n",
        "question = \"What kinds of pets do I like?\"\n",
        "document = \"My favorite pet is a cat.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gS5tBKniSYMG",
        "outputId": "6fd76d31-92b7-4cde-954b-c7968baef839"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tiktoken\n",
        "\n",
        "def num_tokens_from_string(string: str, encoding_name: str) -> int:\n",
        "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
        "    encoding = tiktoken.get_encoding(encoding_name)\n",
        "    num_tokens = len(encoding.encode(string))\n",
        "    return num_tokens\n",
        "\n",
        "num_tokens_from_string(question, \"cl100k_base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAzV8fOnSdCk",
        "outputId": "44b22eee-de8a-4a54-feea-6d1fef0877d6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1536"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "embd = OpenAIEmbeddings()\n",
        "query_result = embd.embed_query(question)\n",
        "document_result = embd.embed_query(document)\n",
        "len(query_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTKBWflpSfRl",
        "outputId": "6f91fce9-d66d-40d2-b755-3e82b19769e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cosine Similarity: 0.8806915835035416\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    dot_product = np.dot(vec1, vec2)\n",
        "    norm_vec1 = np.linalg.norm(vec1)\n",
        "    norm_vec2 = np.linalg.norm(vec2)\n",
        "    return dot_product / (norm_vec1 * norm_vec2)\n",
        "\n",
        "similarity = cosine_similarity(query_result, document_result)\n",
        "print(\"Cosine Similarity:\", similarity)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "gkm-tncrTmUc"
      },
      "outputs": [],
      "source": [
        "# Download documents about IPC/BNS to local directory.\n",
        "os.makedirs(\"legal_doc\", exist_ok=True)\n",
        "files = [\n",
        "    \"https://www.indiacode.nic.in/bitstream/123456789/20062/1/a2023-45.pdf\",\n",
        "    \"https://www.mha.gov.in/sites/default/files/250883_english_01042024.pdf\",\n",
        "\n",
        "]\n",
        "for url in files:\n",
        "    file_path = os.path.join(\"legal_doc\", url.rpartition(\"/\")[2])\n",
        "    urlretrieve(url, file_path)\n",
        "    # Load pdf files in the local directory\n",
        "loader = PyPDFDirectoryLoader(\"./legal_doc/\")\n",
        "\n",
        "blog_docs = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "c6JUntS5SzUL"
      },
      "outputs": [],
      "source": [
        "# Split\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
        "    chunk_size=300,\n",
        "    chunk_overlap=50)\n",
        "\n",
        "# Make splits\n",
        "splits = text_splitter.split_documents(blog_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "vG5NfCq-S10y"
      },
      "outputs": [],
      "source": [
        "# Index\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "vectorstore = Chroma.from_documents(documents=splits,\n",
        "                                    embedding=OpenAIEmbeddings())\n",
        "\n",
        "retriever = vectorstore.as_retriever()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2zdKfyyGS5pv"
      },
      "outputs": [],
      "source": [
        "# Index\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "vectorstore = Chroma.from_documents(documents=splits,\n",
        "                                    embedding=OpenAIEmbeddings())\n",
        "\n",
        "\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 1})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhWiIFeKS8kB",
        "outputId": "f2d33db8-d7d9-40af-8e9a-4fa995813be5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Riddhi Murugan\\AppData\\Local\\Temp\\ipykernel_23616\\1634080666.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  docs = retriever.get_relevant_documents(\"What are offences related to public servants?\")\n"
          ]
        }
      ],
      "source": [
        "docs = retriever.get_relevant_documents(\"What are offences related to public servants?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGAcVkY-S-pT",
        "outputId": "8f2081b6-0ae2-4d2d-e50d-a1ce87a59261"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ue8R_kTTA8p",
        "outputId": "91a996fb-ec9f-40b9-ff18-041e67d537fb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template='Answer the question based only on the following context:\\n{context}\\n\\nQuestion: {question}\\n'), additional_kwargs={})])"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "# Prompt\n",
        "template = \"\"\"Answer the question based only on the following context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "kNJqiRMrTCzn"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "YWhu1qU5TE_G"
      },
      "outputs": [],
      "source": [
        "chain = prompt | llm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPTEE_iZTOKj",
        "outputId": "922fa395-15e5-44d5-aca4-0a5ecf112eb1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='Offences related to public servants include disobeying the law with intent to cause injury, disobeying directions under the law, framing incorrect documents with intent to cause injury, unlawfully engaging in trade, unlawfully buying or bidding for property, personating a public servant, wearing garb or carrying tokens used by public servants with fraudulent intent, absconding to avoid service of summons or other proceedings, preventing service of summons or other proceedings, and non-attendance in obedience to an order from a public servant.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 103, 'prompt_tokens': 283, 'total_tokens': 386, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-60a3a7b0-8056-485d-bab2-b81fd79a628d-0', usage_metadata={'input_tokens': 283, 'output_tokens': 103, 'total_tokens': 386, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Run\n",
        "chain.invoke({\"context\":docs,\"question\":\"What are offences related to public servants?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "JSW_ToWNTQ3i"
      },
      "outputs": [],
      "source": [
        "from langchain import hub\n",
        "prompt_hub_rag = hub.pull(\"rlm/rag-prompt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KX5cIG-VTTnR",
        "outputId": "89b669ec-fc82-4754-9c21-85a2821944d4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt_hub_rag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "QmWu_6YXTV8q",
        "outputId": "38288e03-1f2c-4187-88a9-041f73608484"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Offences related to public servants include disobeying the law with intent to cause injury, disobeying directions under the law, framing incorrect documents with intent to cause injury, unlawfully engaging in trade, unlawfully buying or bidding for property, personating a public servant, wearing garb or carrying tokens used by public servants with fraudulent intent, absconding to avoid service of summons or other proceedings, preventing service of summons or other proceedings, and non-attendance in obedience to an order from a public servant.'"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "rag_chain.invoke(\"What are offences related to public servants?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ipywidgets as widgets\n",
        "from IPython.display import display, HTML, clear_output\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "header = widgets.HTML(value=\"<h1>My Dashboard</h1>\")\n",
        "tabs = widgets.Tab()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Riddhi Murugan\\AppData\\Local\\Temp\\ipykernel_23616\\689421236.py:36: DeprecationWarning:\n",
            "\n",
            "on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "75b27ab2484b46e8a093401896d52c90",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Output(), HBox(children=(Text(value='', layout=Layout(width='70%'), placeholder='Type your ques…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Chat Interface\n",
        "'''class ChatInterface:\n",
        "    def __init__(self, rag_chain):\n",
        "        self.messages = []\n",
        "        self.rag_chain = rag_chain  # Pass the RAG chain as a parameter\n",
        "        \n",
        "        # Create widgets\n",
        "        self.text_input = widgets.Text(\n",
        "            placeholder='Type your question here...',\n",
        "            layout=widgets.Layout(width='70%')\n",
        "        )\n",
        "        self.send_button = widgets.Button(\n",
        "            description='Send',\n",
        "            button_style='primary',\n",
        "            layout=widgets.Layout(width='10%')\n",
        "        )\n",
        "        self.clear_button = widgets.Button(\n",
        "            description='Clear Chat',\n",
        "            button_style='danger',\n",
        "            layout=widgets.Layout(width='10%')\n",
        "        )\n",
        "        \n",
        "        # Create chat display\n",
        "        self.chat_output = widgets.Output()\n",
        "        \n",
        "        # Layout\n",
        "        self.input_box = widgets.HBox([\n",
        "            self.text_input, \n",
        "            self.send_button,\n",
        "            self.clear_button\n",
        "        ])\n",
        "        \n",
        "        # Add button handlers\n",
        "        self.send_button.on_click(self.on_send)\n",
        "        self.clear_button.on_click(self.on_clear)\n",
        "        self.text_input.on_submit(self.on_send)\n",
        "    \n",
        "    def on_send(self, b=None):\n",
        "        question = self.text_input.value.strip()\n",
        "        if question:\n",
        "            self.add_message(question, 'user')\n",
        "            \n",
        "            # Fetch response from the RAG chain\n",
        "            try:\n",
        "                response = self.rag_chain.invoke(question)\n",
        "                self.add_message(response, 'bot')\n",
        "            except Exception as e:\n",
        "                error_message = f\"An error occurred: {str(e)}\"\n",
        "                self.add_message(error_message, 'bot')\n",
        "            \n",
        "            self.text_input.value = ''\n",
        "    \n",
        "    def on_clear(self, b):\n",
        "        with self.chat_output:\n",
        "            clear_output()\n",
        "        self.messages = []\n",
        "    \n",
        "    def add_message(self, message, sender):\n",
        "        # Sanitize message for HTML rendering\n",
        "        sanitized_message = message.replace('<', '&lt;').replace('>', '&gt;')\n",
        "        self.messages.append({'text': sanitized_message, 'sender': sender})\n",
        "        \n",
        "        with self.chat_output:\n",
        "            clear_output()\n",
        "            for msg in self.messages:\n",
        "                msg_class = 'user-message' if msg['sender'] == 'user' else 'bot-message'\n",
        "                display(HTML(f\"\"\"\n",
        "                    <div class=\"chat-container\">\n",
        "                        <div class=\"message {msg_class}\">\n",
        "                            {msg['text']}\n",
        "                        </div>\n",
        "                    </div>\n",
        "                \"\"\"))\n",
        "    \n",
        "    def display(self):\n",
        "        display(widgets.VBox([\n",
        "            self.chat_output,\n",
        "            self.input_box\n",
        "        ]))\n",
        "\n",
        "# Initialize and display the chat interface with the RAG chain\n",
        "chat = ChatInterface(rag_chain)\n",
        "chat.display()'''\n",
        "\n",
        "from IPython.display import HTML, display, clear_output\n",
        "import ipywidgets as widgets\n",
        "\n",
        "# Add CSS for purple theme and chat-like interface\n",
        "display(HTML(\"\"\"\n",
        "<style>\n",
        ".chat-container {\n",
        "    max-width: 800px;\n",
        "    margin: auto;\n",
        "    padding: 20px;\n",
        "    background-color: #f9f9f9;\n",
        "    border-radius: 10px;\n",
        "}\n",
        "\n",
        ".message {\n",
        "    padding: 10px 15px;\n",
        "    margin: 5px;\n",
        "    border-radius: 15px;\n",
        "    max-width: 70%;\n",
        "    word-wrap: break-word;\n",
        "}\n",
        "\n",
        ".user-message {\n",
        "    background-color: #6a4c9c;\n",
        "    color: white;\n",
        "    margin-left: auto;\n",
        "    text-align: right;\n",
        "}\n",
        "\n",
        ".bot-message {\n",
        "    background-color: #e3d9f3;\n",
        "    margin-right: auto;\n",
        "    text-align: left;\n",
        "}\n",
        "\n",
        ".input-container {\n",
        "    background-color: #f1f1f1;\n",
        "    padding: 10px;\n",
        "    border-radius: 10px;\n",
        "    margin-top: 20px;\n",
        "}\n",
        "\n",
        ".text-box {\n",
        "    width: 75%;\n",
        "    padding: 10px;\n",
        "    border-radius: 5px;\n",
        "    border: 1px solid #ccc;\n",
        "}\n",
        "\n",
        ".send-button {\n",
        "    background-color: #6a4c9c;\n",
        "    color: white;\n",
        "    padding: 10px 20px;\n",
        "    border: none;\n",
        "    border-radius: 5px;\n",
        "    cursor: pointer;\n",
        "    margin-left: 10px;\n",
        "}\n",
        "\n",
        ".send-button:hover {\n",
        "    background-color: #5a3f7d;\n",
        "}\n",
        "\n",
        ".clear-button {\n",
        "    background-color: #db3d44;\n",
        "    color: white;\n",
        "    padding: 10px 20px;\n",
        "    border: none;\n",
        "    border-radius: 5px;\n",
        "    cursor: pointer;\n",
        "    margin-left: 10px;\n",
        "}\n",
        "\n",
        ".clear-button:hover {\n",
        "    background-color: #c22e31;\n",
        "}\n",
        "</style>\n",
        "\"\"\"))\n",
        "\n",
        "# Chat Interface\n",
        "class ChatInterface:\n",
        "    def __init__(self, rag_chain):\n",
        "        self.messages = []\n",
        "        self.rag_chain = rag_chain  # Pass the RAG chain as a parameter\n",
        "        \n",
        "        # Create widgets\n",
        "        self.text_input = widgets.Text(\n",
        "            placeholder='Type your question here...',\n",
        "            layout=widgets.Layout(width='75%', padding='10px', border='1px solid #ccc', border_radius='5px')\n",
        "        )\n",
        "        self.send_button = widgets.Button(\n",
        "            description='Send',\n",
        "            button_style='primary',\n",
        "            layout=widgets.Layout(width='10%')\n",
        "        )\n",
        "        self.clear_button = widgets.Button(\n",
        "            description='Clear Chat',\n",
        "            button_style='danger',\n",
        "            layout=widgets.Layout(width='15%')\n",
        "        )\n",
        "        \n",
        "        # Create chat display\n",
        "        self.chat_output = widgets.Output()\n",
        "        \n",
        "        # Layout\n",
        "        self.input_box = widgets.HBox([\n",
        "            self.text_input, \n",
        "            self.send_button,\n",
        "            self.clear_button\n",
        "        ])\n",
        "        \n",
        "        # Add button handlers\n",
        "        self.send_button.on_click(self.on_send)\n",
        "        self.clear_button.on_click(self.on_clear)\n",
        "        self.text_input.on_submit(self.on_send)\n",
        "    \n",
        "    def on_send(self, b=None):\n",
        "        question = self.text_input.value.strip()\n",
        "        if question:\n",
        "            self.add_message(question, 'user')\n",
        "            \n",
        "            # Fetch response from the RAG chain\n",
        "            try:\n",
        "                response = self.rag_chain.invoke(question)\n",
        "                self.add_message(response, 'bot')\n",
        "            except Exception as e:\n",
        "                error_message = f\"An error occurred: {str(e)}\"\n",
        "                self.add_message(error_message, 'bot')\n",
        "            \n",
        "            self.text_input.value = ''\n",
        "    \n",
        "    def on_clear(self, b):\n",
        "        with self.chat_output:\n",
        "            clear_output()\n",
        "        self.messages = []\n",
        "    \n",
        "    def add_message(self, message, sender):\n",
        "        # Sanitize message for HTML rendering\n",
        "        sanitized_message = message.replace('<', '&lt;').replace('>', '&gt;')\n",
        "        self.messages.append({'text': sanitized_message, 'sender': sender})\n",
        "        \n",
        "        with self.chat_output:\n",
        "            clear_output()\n",
        "            for msg in self.messages:\n",
        "                msg_class = 'user-message' if msg['sender'] == 'user' else 'bot-message'\n",
        "                display(HTML(f\"\"\"\n",
        "                    <div class=\"chat-container\">\n",
        "                        <div class=\"message {msg_class}\">\n",
        "                            {msg['text']}\n",
        "                        </div>\n",
        "                    </div>\n",
        "                \"\"\"))\n",
        "    \n",
        "    def display(self):\n",
        "        display(widgets.VBox([\n",
        "            self.chat_output,\n",
        "            self.input_box\n",
        "        ]))\n",
        "\n",
        "# Initialize and display the chat interface with the RAG chain\n",
        "chat = ChatInterface(rag_chain)\n",
        "chat.display()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOFYJpZ5ZSORey/21guMBP/",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
